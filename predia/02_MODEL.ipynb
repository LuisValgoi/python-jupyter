{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set predictions: [0 1 1 1 0 1 2 2 2 2 1 2 1 1 0 0 0 1 0 1 2 1 1 1 2 1 0 2 0 2 2 2 0 0 0 0 2\n",
      " 1]\n",
      "Test set accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Generate the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# Build a model using the default setting of fully developing the tree\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# Fit the classifier on training set\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Make the predictions on test set\n",
    "predictions = tree.predict(X_test)\n",
    "print(\"Test set predictions: {}\".format(predictions))\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = tree.score(X_test, y_test)\n",
    "print(\"Test set accuracy: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (526, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-421-4310630e35ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;31m# training the model and get its score - BayesianRidge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0mmodel7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m \u001b[0mmodel7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0maccuracy7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'AcurÃ¡cia do BayesianRidge: {round(accuracy7*100, 2)}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    191\u001b[0m                              ' Got {!r}.'.format(self.n_iter))\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    758\u001b[0m                         dtype=None)\n\u001b[1;32m    759\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (526, 2)"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mpld3\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing, svm\n",
    "from matplotlib import style\n",
    "\n",
    "# configs\n",
    "mpld3.enable_notebook()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# read csvs & build dataframe\n",
    "df = pd.DataFrame()\n",
    "df_temp = pd.read_csv('./datasets/temperatura_featured.csv')\n",
    "df_vendas = pd.read_csv('./datasets/vendas.csv', ';')\n",
    "df_conc = pd.read_csv('./datasets/concorrentes.csv', ';')\n",
    "\n",
    "# pre processing\n",
    "def get_dias_fechados():\n",
    "    return ['2018-03-30', '2018-11-02', '2018-12-25', '2018-12-29', '2018-12-30', '2018-12-31', '2019-01-01', '2019-03-03', '2019-03-04', '2019-03-05', '2019-04-19', '2019-11-02', '2019-12-25', '2019-12-29', '2019-12-30', '2019-12-31', '2020-01-01', '2020-02-24', '2020-02-25']\n",
    "\n",
    "def get_dias_fds():\n",
    "    return ['Sunday', 'Saturday']\n",
    "\n",
    "def get_dias_feriados():\n",
    "    return ['2018-03-30', '2018-04-21', '2018-04-30', '2018-05-01', '2018-05-31', '2018-06-01', '2018-09-07', '2018-10-12', '2018-11-02', '2018-11-15', '2018-11-16', '2018-12-24', '2018-12-25', '2018-12-29', '2018-12-30', '2018-12-31', \n",
    "'2019-01-01', '2019-03-04', '2019-03-05', '2019-04-19', '2019-04-21', '2019-05-01', '2019-06-20', '2019-06-21', '2019-09-07', '2019-10-12', '2019-11-02', '2019-11-15', '2019-12-25', '2019-12-25', '2019-12-25', '2019-12-30', '2019-12-31', \n",
    "'2020-01-01', '2020-02-24', '2020-02-25']\n",
    "\n",
    "def get_dias_festivos():\n",
    "    return ['2018-05-13', '2018-08-12', '2018-12-25', '2018-12-29', '2018-12-30', '2018-12-31', '2019-01-01', '2019-03-03', '2019-03-04', '2019-03-05', '2019-05-12', '2019-08-11', '2019-12-25', '2019-12-29', '2019-12-30', '2019-12-31', '2020-01-01', '2020-02-24', '2020-02-25']\n",
    "\n",
    "def get_vesperas_dias_festivos():\n",
    "    vesperas = []\n",
    "    for i in range(len(get_dias_festivos())):\n",
    "        vesperas_dia_festivo_current = pd.Series(pd.date_range(end=get_dias_festivos()[i], periods=5, closed='left'))\n",
    "        for j in range(len(vesperas_dia_festivo_current)):\n",
    "            vesperas.append(vesperas_dia_festivo_current[j])\n",
    "    return vesperas\n",
    "\n",
    "def get_pos_dias_festivos():\n",
    "    pos = []\n",
    "    for i in range(len(get_dias_festivos())):\n",
    "        pos_dia_festivo_current = pd.Series(pd.date_range(get_dias_festivos()[i], periods=3, closed='right'))\n",
    "        for j in range(len(pos_dia_festivo_current)):\n",
    "            pos.append(pos_dia_festivo_current[j])\n",
    "    return pos\n",
    "\n",
    "def get_dias_acerca_pagamento():\n",
    "    return [5,6,7,8,9,10,28,29,30,31]\n",
    "\n",
    "def get_meses_baixas_temporadas():\n",
    "    return [1, 2]\n",
    "\n",
    "# featured engineering\n",
    "df.insert(loc=0, column='DATA', value=(pd.to_datetime(df_vendas['DATA']).dt.strftime(\"%Y%m%d\")))\n",
    "df.insert(loc=1, column='VENDAS', value=(df_vendas['VENDAS'].fillna(0).astype(int)))\n",
    "df.insert(loc=2, column='IS_FECHADO', value=(pd.DatetimeIndex(df_temp['DATA']).isin(get_dias_fechados()).astype(int)))\n",
    "df.insert(loc=3, column='IS_FDS', value=(pd.DatetimeIndex(df_temp['DATA']).day_name().isin(get_dias_fds())).astype(int))\n",
    "df.insert(loc=4, column='IS_FERIADO', value=(pd.DatetimeIndex(df_temp['DATA']).isin(get_dias_feriados())).astype(int))\n",
    "df.insert(loc=5, column='IS_DATA_FESTIVA', value=(pd.DatetimeIndex(df_temp['DATA']).isin(get_dias_festivos())).astype(int))\n",
    "df.insert(loc=6, column='IS_VESPERA_DATA_FESTIVA', value=(pd.DatetimeIndex(df_temp['DATA']).isin(get_vesperas_dias_festivos())).astype(int))\n",
    "df.insert(loc=7, column='IS_POS_DATA_FESTIVA', value=(pd.DatetimeIndex(df_temp['DATA']).isin(get_pos_dias_festivos())).astype(int))\n",
    "df.insert(loc=8, column='IS_SEMANA_PAGAMENTO', value=(pd.DatetimeIndex(df_temp['DATA']).day.astype(int).isin(get_dias_acerca_pagamento()).astype(int)))\n",
    "df.insert(loc=9, column='IS_BAIXA_TEMPORADA', value=(pd.DatetimeIndex(df_temp['DATA']).month.isin(get_meses_baixas_temporadas()).astype(int)))\n",
    "df.insert(loc=10, column='QTD_CONCORRENTES', value=(df_conc['CONCORRENTES'].fillna(0).astype(int)))\n",
    "df.insert(loc=11, column='PRECIPITACAO', value=(df_temp['PRECIPITACAO']))\n",
    "df.insert(loc=12, column='TEMPERATURA', value=(df_temp['TEMPERATURA']))\n",
    "df.insert(loc=13, column='UMIDADE', value=(df_temp['UMIDADE']))\n",
    "\n",
    "# input & output\n",
    "X = df.drop(columns=['DATA', 'VENDAS'])\n",
    "# y = df.drop(columns=['DATA', 'IS_FECHADO', 'IS_FDS', 'IS_FERIADO', 'IS_DATA_FESTIVA', 'IS_VESPERA_DATA_FESTIVA', 'IS_POS_DATA_FESTIVA', 'IS_SEMANA_PAGAMENTO', 'IS_BAIXA_TEMPORADA', 'QTD_CONCORRENTES', 'PRECIPITACAO', 'TEMPERATURA', 'UMIDADE'])\n",
    "X = df.drop(columns=['VENDAS'])\n",
    "y = df.drop(columns=['IS_FECHADO', 'IS_FDS', 'IS_FERIADO', 'IS_DATA_FESTIVA', 'IS_VESPERA_DATA_FESTIVA', 'IS_POS_DATA_FESTIVA', 'IS_SEMANA_PAGAMENTO', 'IS_BAIXA_TEMPORADA', 'QTD_CONCORRENTES', 'PRECIPITACAO', 'TEMPERATURA', 'UMIDADE'])\n",
    "\n",
    "# standardization & normalization\n",
    "X = preprocessing.scale(X)\n",
    "\n",
    "# shuffled and splitted into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) \n",
    "\n",
    "# training the model and get its score - LinearRegression\n",
    "model = LinearRegression(n_jobs=-1) \n",
    "model.fit(X_train, y_train)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'AcurÃ¡cia do LinearRegression: {round(accuracy*100, 2)}%')\n",
    "\n",
    "# training the model and get its score - Support Vector Regression\n",
    "model2 = svm.SVR(kernel='poly')\n",
    "model2.fit(X_train, y_train)\n",
    "accuracy2 = model2.score(X_test, y_test)\n",
    "print(f'AcurÃ¡cia do Vector Regression: {round(accuracy2*100, 2)}%')\n",
    "\n",
    "# training the model and get its score - DecisionTreeClassifier\n",
    "model3 = DecisionTreeClassifier(criterion = 'entropy', random_state = 42)\n",
    "model3.fit(X_train, y_train)\n",
    "accuracy3 = model3.score(X_test, y_test)\n",
    "print(f'AcurÃ¡cia do DecisionTreeClassifier: {round(accuracy3*100, 2)}%')\n",
    "\n",
    "# training the model and get its score - DecisionTreeRegressor\n",
    "model4 = DecisionTreeRegressor(random_state=0)\n",
    "model4.fit(X_train, y_train)\n",
    "accuracy4 = model4.score(X_test, y_test)\n",
    "print(f'AcurÃ¡cia do DecisionTreeRegressor: {round(accuracy4*100, 2)}%')\n",
    "\n",
    "# training the model and get its score - AdaBoostRegressor\n",
    "model5 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=14), n_estimators=300, learning_rate=2, loss='exponential')\n",
    "model5.fit(X_train, y_train)\n",
    "accuracy5 = model5.score(X_test, y_test)\n",
    "print(f'AcurÃ¡cia do AdaBoostRegressor: {round(accuracy5*100, 2)}%')\n",
    "\n",
    "# training the model and get its score - RandomForestClassifier\n",
    "model6 = RandomForestClassifier(criterion = 'entropy', random_state = 42)\n",
    "model6.fit(X_train, y_train)\n",
    "accuracy6 = model6.score(X_test, y_test)\n",
    "print(f'AcurÃ¡cia do RandomForestClassifier: {round(accuracy6*100, 2)}%')\n",
    "\n",
    "# training the model and get its score - BayesianRidge\n",
    "model7 = BayesianRidge(compute_score=True)\n",
    "model7.fit(X_train, y_train)\n",
    "accuracy7 = model7.score(X_test, y_test)\n",
    "print(f'AcurÃ¡cia do BayesianRidge: {round(accuracy7*100, 2)}%')\n",
    "\n",
    "# create forecast column\n",
    "# df.insert(loc=2, column='VENDAS_FORECAST', value=(np.nan))\n",
    "\n",
    "# plot chart\n",
    "df.plot(y='VENDAS', x='DATA', figsize=(13, 4), linestyle='solid', linewidth=1, markersize=2, style=\"-o\")\n",
    "plt.legend(loc=1)\n",
    "plt.title('HISTÃRICO DE VENDAS')\n",
    "plt.xlabel('DATA')\n",
    "plt.ylabel('QUANTIDADE DE ALMOÃOS')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
